# ğŸ§ª Agricultural SRI System - Testing Guide

## âš ï¸ Current Status

I've prepared your system for testing:
- âœ… Created `.env` file with test configuration
- âœ… Fixed docker-compose.yml (removed deprecated version)
- âœ… Created Dockerfile for FastAPI server
- âœ… All code files are ready

**Docker is currently unresponsive** - you'll need to restart Docker Desktop first.

---

## ğŸ”§ Step 1: Restart Docker Desktop

Docker commands are timing out. Please restart Docker Desktop:

1. **Quit Docker Desktop completely**
   - Click Docker icon in menu bar
   - Select "Quit Docker Desktop"
   - Wait 10 seconds

2. **Start Docker Desktop again**
   - Open Docker Desktop application
   - Wait for it to fully start (icon turns solid)
   - You should see "Docker Desktop is running" in the menu

3. **Verify Docker is working**
   ```bash
   docker ps
   ```
   This should return quickly with a list of containers (may be empty).

---

## ğŸš€ Step 2: Start the Services

Once Docker is responsive, start the Airflow system:

```bash
# Navigate to docker directory
cd /Users/osmanorka/Farm_Stock_Predit/airflow_production/docker

# Start all services
docker compose up -d
```

**Expected output:**
```
[+] Running 7/7
 âœ” Network docker_default          Created
 âœ” Container docker-postgres-1      Started
 âœ” Container docker-redis-1         Started
 âœ” Container docker-airflow-init-1  Started
 âœ” Container docker-api-server-1    Started
 âœ” Container docker-airflow-webserver-1  Started
 âœ” Container docker-airflow-scheduler-1  Started
 âœ” Container docker-airflow-worker-1     Started
```

**This will take 2-3 minutes on first run** (pulling images and initializing).

---

## ğŸ“Š Step 3: Verify Services Are Running

Check that all services started successfully:

```bash
docker compose ps
```

**Expected output - all services should show "Up" or "healthy":**
```
NAME                             STATUS
docker-airflow-scheduler-1       Up (healthy)
docker-airflow-webserver-1       Up (healthy)
docker-airflow-worker-1          Up (healthy)
docker-api-server-1              Up
docker-postgres-1                Up (healthy)
docker-redis-1                   Up (healthy)
```

If any service shows "Exited" or "unhealthy", check logs:
```bash
docker compose logs <service-name>
```

---

## ğŸŒ Step 4: Access Airflow UI

1. **Open your web browser** and go to:
   ```
   http://localhost:8080
   ```

2. **Login with credentials:**
   - Username: `admin`
   - Password: `test_password_123`

3. **You should see the Airflow UI** with the DAG list.

---

## ğŸ¯ Step 5: Find and Unpause the DAG

1. In the Airflow UI, look for the DAG named:
   ```
   agricultural_sri_annual_report
   ```

2. **Unpause the DAG:**
   - Toggle the switch on the left side to ON (blue)
   - This enables the DAG for execution

3. **View DAG details:**
   - Click on the DAG name
   - You'll see the DAG graph showing all 5 stages

---

## ğŸš¦ Step 6: Trigger a Test Run

### Option A: Via Web UI (Recommended)

1. Click on the DAG name: `agricultural_sri_annual_report`
2. Click the **"Play" button** (â–¶ï¸) in the top right
3. Select **"Trigger DAG"**
4. Click **"Trigger"** to confirm

### Option B: Via Command Line

```bash
docker compose exec airflow-webserver \
  airflow dags trigger agricultural_sri_annual_report
```

---

## ğŸ“ˆ Step 7: Monitor Execution

### Watch in Real-Time:

1. **In Airflow UI**, click on the DAG run (you'll see a new row appear)
2. Click **"Graph"** view to see task progress
3. Tasks will change colors:
   - **Gray** = Not started
   - **Yellow** = Running
   - **Green** = Success
   - **Red** = Failed

### Expected Execution Flow:

```
Stage 1: Data Collection (5-10 min)
â”œâ”€ wait_for_data_availability âœ“
â”œâ”€ fetch_crop_yield âœ“
â”œâ”€ fetch_weather âš ï¸ (may fail if no API key)
â”œâ”€ fetch_drought âœ“
â””â”€ fetch_economic âœ“

Stage 2: Data Processing (2 min)
â”œâ”€ validate_data âœ“
â””â”€ merge_datasets âœ“

Stage 3: SRI Calculation (3 min)
â”œâ”€ calculate_sri âœ“
â”œâ”€ validate_sri âœ“
â””â”€ compare_with_previous_year âœ“

Stage 4: Report Generation (5 min)
â”œâ”€ generate_market_summary âœ“
â”œâ”€ generate_state_reports âœ“
â””â”€ generate_visualizations âœ“

Stage 5: Distribution (2 min)
â”œâ”€ upload_to_s3 âš ï¸ (skipped - no AWS key)
â”œâ”€ update_api_database âœ“
â””â”€ send_email_notifications âš ï¸ (skipped - no SMTP)

âœ… COMPLETE!
```

**Total time: ~20-30 minutes**

---

## ğŸ” Step 8: View Results

### Check Generated Files:

```bash
# Navigate to data directory
cd /Users/osmanorka/Farm_Stock_Predit/airflow_production/data

# View directory structure
tree -L 3 .
```

**Expected output:**
```
data/
â”œâ”€â”€ raw/2024/
â”‚   â”œâ”€â”€ crop_yield_2024.csv
â”‚   â”œâ”€â”€ weather_2024.csv (if API key provided)
â”‚   â”œâ”€â”€ drought_2024.csv
â”‚   â””â”€â”€ economic_2024.csv
â”‚
â”œâ”€â”€ processed/2024/
â”‚   â””â”€â”€ merged_data_2024.csv
â”‚
â”œâ”€â”€ results/2024/
â”‚   â””â”€â”€ sri_results_2024.csv
â”‚
â””â”€â”€ reports/2024/
    â”œâ”€â”€ market_summary_2024.html
    â”œâ”€â”€ states/
    â”‚   â””â”€â”€ [50 state CSV files]
    â””â”€â”€ visualizations/
        â””â”€â”€ [5 PNG charts]
```

### View the Market Summary Report:

```bash
# Open the HTML report in your browser
open data/reports/2024/market_summary_2024.html
```

You should see a professional report with:
- Executive summary
- Critical alerts
- Top risk states
- Commodity analysis

---

## ğŸ”Œ Step 9: Test the API

### Check API Health:

```bash
curl http://localhost:8000/health
```

**Expected response:**
```json
{
  "status": "healthy",
  "timestamp": "2025-10-18T...",
  "data_available": true,
  "available_years": [2024],
  "latest_year": 2024
}
```

### Get Latest SRI Data:

```bash
curl http://localhost:8000/sri/latest | jq
```

### View API Documentation:

Open in your browser:
```
http://localhost:8000/docs
```

You'll see interactive API documentation with all 10+ endpoints.

---

## ğŸ› Troubleshooting

### Issue: Services won't start

```bash
# Check logs
docker compose logs -f

# Restart everything
docker compose down
docker compose up -d
```

### Issue: Airflow UI shows error

```bash
# Check webserver logs
docker compose logs airflow-webserver

# Restart webserver
docker compose restart airflow-webserver
```

### Issue: DAG not visible

```bash
# Check DAG for syntax errors
docker compose exec airflow-webserver \
  python /opt/airflow/dags/agricultural_sri_pipeline.py

# Restart scheduler
docker compose restart airflow-scheduler
```

### Issue: Tasks fail with "Module not found"

```bash
# Install missing dependencies
docker compose exec airflow-worker \
  pip install <package-name>

# Or rebuild containers
docker compose down
docker compose build --no-cache
docker compose up -d
```

### Issue: Weather data collection fails

This is expected if you don't have a Visual Crossing API key. The pipeline will continue with other data sources.

---

## ğŸ“ View Task Logs

To see detailed logs of any task:

1. In Airflow UI, click on the task (colored box)
2. Click **"Log"** button
3. View execution logs in detail

Or via command line:
```bash
docker compose exec airflow-worker \
  airflow tasks test agricultural_sri_annual_report fetch_crop_yield 2024-10-01
```

---

## ğŸ›‘ Stop the System

When you're done testing:

```bash
# Stop all services
docker compose down

# Stop and remove data volumes (clean slate)
docker compose down -v
```

---

## âœ… Success Indicators

Your test is successful if:

- âœ… All services start and show "healthy" status
- âœ… Airflow UI is accessible at http://localhost:8080
- âœ… DAG appears in the list
- âœ… DAG run completes (all tasks green)
- âœ… Market summary HTML is generated
- âœ… SRI results CSV is created
- âœ… API returns data at http://localhost:8000/sri/latest

---

## ğŸ“ Next Steps After Testing

Once testing is successful:

1. **Add real API keys** to `.env`:
   - Visual Crossing for weather data
   - AWS credentials for S3 storage (optional)
   - Gmail SMTP for email alerts

2. **Configure stakeholder emails** in `.env`

3. **Set production schedule** (default is October 1st annually)

4. **Deploy to production server** (optional)

---

## ğŸ’¡ Quick Commands Reference

```bash
# Start system
docker compose up -d

# Check status
docker compose ps

# View all logs
docker compose logs -f

# View specific service logs
docker compose logs -f airflow-scheduler

# Stop system
docker compose down

# Restart single service
docker compose restart airflow-webserver

# Access Airflow CLI
docker compose exec airflow-webserver airflow <command>

# Access worker shell
docker compose exec airflow-worker bash
```

---

**Ready to test!** Follow the steps above and let me know if you encounter any issues. ğŸš€
