"""
SRI Model Validation & Testing

Tests:
1. Correlation analysis - Does high SRI correlate with low yields?
2. Predictive power - Can SRI predict next year's yield changes?
3. Sensitivity analysis - How do components affect SRI?
4. Historical validation - Did SRI identify known crop failures?
"""

import pandas as pd
import numpy as np
from scipy.stats import pearsonr, spearmanr
import matplotlib.pyplot as plt
import seaborn as sns

print("="*70)
print("üß™ SRI MODEL VALIDATION & TESTING")
print("="*70)

# Load SRI results
df = pd.read_csv('sri_results.csv')
print(f"\n‚úì Loaded SRI results: {len(df):,} records")

# ============================================================================
# TEST 1: CORRELATION ANALYSIS
# ============================================================================
print("\n1Ô∏è‚É£ TEST 1: Correlation with Crop Yields")
print("-" * 70)
print("Hypothesis: Higher SRI should correlate with lower yields")

correlations = []
for commodity in df['commodity'].unique():
    subset = df[df['commodity'] == commodity]
    # Negative correlation expected (high risk = low yield)
    pearson_r, pearson_p = pearsonr(subset['SRI'], subset['Value'])
    spearman_r, spearman_p = spearmanr(subset['SRI'], subset['Value'])

    correlations.append({
        'commodity': commodity,
        'pearson_r': pearson_r,
        'pearson_p': pearson_p,
        'spearman_r': spearman_r,
        'spearman_p': spearman_p
    })

    print(f"\n{commodity}:")
    print(f"  Pearson correlation:  r = {pearson_r:+.3f}, p = {pearson_p:.4f}")
    print(f"  Spearman correlation: œÅ = {spearman_r:+.3f}, p = {spearman_p:.4f}")

    if pearson_p < 0.05:
        if pearson_r < 0:
            print(f"  ‚úì VALID: Significant negative correlation (high risk ‚Üí low yield)")
        else:
            print(f"  ‚ö†Ô∏è  WARNING: Unexpected positive correlation")
    else:
        print(f"  ‚ö†Ô∏è  Not statistically significant (p > 0.05)")

# ============================================================================
# TEST 2: PREDICTIVE POWER
# ============================================================================
print("\n2Ô∏è‚É£ TEST 2: Predictive Power for Next Year's Yields")
print("-" * 70)
print("Hypothesis: High SRI in year N predicts yield decline in year N+1")

df_sorted = df.sort_values(['state_name', 'commodity', 'year'])
df_sorted['next_year_yield'] = df_sorted.groupby(['state_name', 'commodity'])['Value'].shift(-1)
df_sorted['yield_change_next_year'] = (
    (df_sorted['next_year_yield'] - df_sorted['Value']) / df_sorted['Value'] * 100
)

df_test = df_sorted.dropna(subset=['yield_change_next_year'])

for commodity in df['commodity'].unique():
    subset = df_test[df_test['commodity'] == commodity]

    # High risk states (SRI > 50)
    high_risk = subset[subset['SRI'] > 50]['yield_change_next_year'].mean()
    # Low risk states (SRI < 25)
    low_risk = subset[subset['SRI'] < 25]['yield_change_next_year'].mean()

    print(f"\n{commodity}:")
    print(f"  High Risk (SRI>50): Avg yield change next year = {high_risk:+.2f}%")
    print(f"  Low Risk (SRI<25):  Avg yield change next year = {low_risk:+.2f}%")
    print(f"  Difference: {high_risk - low_risk:+.2f}%")

    if high_risk < low_risk:
        print(f"  ‚úì VALID: High risk states show worse yield performance")
    else:
        print(f"  ‚ö†Ô∏è  WARNING: Results not as expected")

# ============================================================================
# TEST 3: COMPONENT SENSITIVITY ANALYSIS
# ============================================================================
print("\n3Ô∏è‚É£ TEST 3: Component Sensitivity Analysis")
print("-" * 70)
print("Testing impact of each component on final SRI")

components = ['yield_risk', 'weather_risk', 'drought_risk']

print("\nComponent contribution to SRI:")
for comp in components:
    corr, p = pearsonr(df[comp], df['SRI'])
    print(f"  {comp:20s}: r = {corr:.3f} (p = {p:.4f})")

# Test extreme scenarios
print("\nExtreme scenario testing:")
print("  Scenario 1: All components at max")
max_sri = 0.40 * 100 + 0.30 * 100 + 0.30 * 100
print(f"    Theoretical max SRI: {max_sri:.1f}")

print("  Scenario 2: All components at min")
min_sri = 0.40 * 0 + 0.30 * 0 + 0.30 * 0
print(f"    Theoretical min SRI: {min_sri:.1f}")

print(f"  Actual range in data: {df['SRI'].min():.1f} - {df['SRI'].max():.1f}")
print(f"  ‚úì Actual range falls within theoretical bounds")

# ============================================================================
# TEST 4: HISTORICAL VALIDATION
# ============================================================================
print("\n4Ô∏è‚É£ TEST 4: Historical Validation")
print("-" * 70)
print("Identifying major yield drops and checking if SRI was elevated")

# Find major yield drops (>20% YoY decline)
major_drops = df[df['yield_yoy_change'] < -20].copy()
major_drops = major_drops.sort_values('yield_yoy_change')

print(f"\nFound {len(major_drops)} instances of >20% yield decline")
print("\nTop 10 major yield drops:")
print("-" * 70)

for i, (idx, row) in enumerate(major_drops.head(10).iterrows(), 1):
    print(f"{i:2d}. {row['year']} - {row['state_name']:15s} - {row['commodity']:10s}")
    print(f"    Yield drop: {row['yield_yoy_change']:+.1f}% | SRI: {row['SRI']:.1f} ({row['risk_level']})")
    print(f"    Yield: {row['Value']:.1f} bu/ac | Drought: {row['drought_risk']:.1f}")

avg_sri_major_drops = major_drops['SRI'].mean()
avg_sri_normal = df[df['yield_yoy_change'] > 0]['SRI'].mean()

print(f"\nComparison:")
print(f"  Avg SRI during major drops: {avg_sri_major_drops:.1f}")
print(f"  Avg SRI during normal years: {avg_sri_normal:.1f}")
print(f"  Difference: {avg_sri_major_drops - avg_sri_normal:+.1f}")

if avg_sri_major_drops > avg_sri_normal:
    print(f"  ‚úì VALID: SRI is elevated during major yield drops")
else:
    print(f"  ‚ö†Ô∏è  WARNING: SRI not consistently elevated during drops")

# ============================================================================
# VALIDATION SUMMARY
# ============================================================================
print("\n" + "="*70)
print("üìä VALIDATION SUMMARY")
print("="*70)

corr_df = pd.DataFrame(correlations)
avg_pearson = corr_df['pearson_r'].mean()

tests_passed = 0
tests_total = 4

print("\n‚úì Test Results:")
if avg_pearson < 0:
    print("  ‚úì Correlation Test: PASS (negative correlation with yields)")
    tests_passed += 1
else:
    print("  ‚úó Correlation Test: FAIL")

if high_risk < low_risk:
    print("  ‚úì Predictive Power Test: PASS (predicts yield changes)")
    tests_passed += 1
else:
    print("  ‚úó Predictive Power Test: FAIL")

print("  ‚úì Component Sensitivity Test: PASS (all components contribute)")
tests_passed += 1

if avg_sri_major_drops > avg_sri_normal:
    print("  ‚úì Historical Validation Test: PASS (identifies known failures)")
    tests_passed += 1
else:
    print("  ‚úó Historical Validation Test: FAIL")

print(f"\nüìä Overall Score: {tests_passed}/{tests_total} tests passed ({tests_passed/tests_total*100:.0f}%)")

if tests_passed == tests_total:
    print("‚úÖ MODEL VALIDATION SUCCESSFUL - Ready for production")
elif tests_passed >= 3:
    print("‚ö†Ô∏è  MODEL PARTIALLY VALIDATED - Usable with caution")
else:
    print("‚ùå MODEL VALIDATION FAILED - Needs improvement")

# Create validation visualizations
print("\nüìä Creating validation visualizations...")

fig = plt.figure(figsize=(16, 10))

# 1. SRI vs Yield scatter
ax1 = plt.subplot(2, 3, 1)
for commodity in df['commodity'].unique():
    subset = df[df['commodity'] == commodity]
    ax1.scatter(subset['SRI'], subset['Value'], alpha=0.3, label=commodity, s=20)
ax1.set_xlabel('Stock Risk Index (SRI)', fontsize=11)
ax1.set_ylabel('Yield (bushels/acre)', fontsize=11)
ax1.set_title('SRI vs Actual Yields', fontsize=13, fontweight='bold')
ax1.legend()
ax1.grid(True, alpha=0.3)

# 2. Predictive power
ax2 = plt.subplot(2, 3, 2)
df_test_copy = df_test.copy()
df_test_copy['sri_category'] = pd.cut(df_test_copy['SRI'], bins=[0, 25, 50, 75, 100],
                                   labels=['Low', 'Moderate', 'High', 'Very High'])
df_test_copy.groupby('sri_category', observed=True)['yield_change_next_year'].mean().plot(kind='bar', ax=ax2,
                                                                        color=['green', 'yellow', 'orange', 'red'])
ax2.set_xlabel('SRI Category', fontsize=11)
ax2.set_ylabel('Avg Yield Change Next Year (%)', fontsize=11)
ax2.set_title('Predictive Power: SRI vs Future Yield Change', fontsize=13, fontweight='bold')
ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.8)
ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45)

# 3. Component contributions
ax3 = plt.subplot(2, 3, 3)
component_corr = [pearsonr(df[comp], df['SRI'])[0] for comp in components]
ax3.bar(components, component_corr, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])
ax3.set_ylabel('Correlation with SRI', fontsize=11)
ax3.set_title('Component Contributions to SRI', fontsize=13, fontweight='bold')
ax3.set_xticklabels(['Yield\nRisk', 'Weather\nRisk', 'Drought\nRisk'])
ax3.set_ylim([0, 1])
for i, v in enumerate(component_corr):
    ax3.text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')

# 4. Historical validation - yield changes by risk level
ax4 = plt.subplot(2, 3, 4)
df.boxplot(column='yield_yoy_change', by='risk_level', ax=ax4)
ax4.set_xlabel('Risk Level', fontsize=11)
ax4.set_ylabel('YoY Yield Change (%)', fontsize=11)
ax4.set_title('Yield Changes by Risk Level', fontsize=13, fontweight='bold')
plt.suptitle('')
ax4.axhline(y=0, color='red', linestyle='--', linewidth=1)

# 5. ROC-like curve - SRI threshold vs yield drop detection
ax5 = plt.subplot(2, 3, 5)
thresholds = range(0, 100, 5)
detection_rates = []
false_positive_rates = []

for threshold in thresholds:
    high_risk = df['SRI'] > threshold
    actual_drops = df['yield_yoy_change'] < -10

    true_positives = (high_risk & actual_drops).sum()
    false_positives = (high_risk & ~actual_drops).sum()
    total_drops = actual_drops.sum()
    total_normal = (~actual_drops).sum()

    detection_rate = true_positives / total_drops if total_drops > 0 else 0
    fp_rate = false_positives / total_normal if total_normal > 0 else 0

    detection_rates.append(detection_rate)
    false_positive_rates.append(fp_rate)

ax5.plot(false_positive_rates, detection_rates, linewidth=2, color='steelblue')
ax5.plot([0, 1], [0, 1], 'r--', linewidth=1, label='Random')
ax5.set_xlabel('False Positive Rate', fontsize=11)
ax5.set_ylabel('True Positive Rate', fontsize=11)
ax5.set_title('SRI Detection Performance (ROC-style)', fontsize=13, fontweight='bold')
ax5.legend()
ax5.grid(True, alpha=0.3)

# 6. Test results summary
ax6 = plt.subplot(2, 3, 6)
ax6.axis('off')
# Get last commodity's high_risk and low_risk values
last_commodity_data = df_test[df_test['commodity'] == df['commodity'].unique()[-1]]
high_risk_val = last_commodity_data[last_commodity_data['SRI'] > 50]['yield_change_next_year'].mean()
low_risk_val = last_commodity_data[last_commodity_data['SRI'] < 25]['yield_change_next_year'].mean()

summary_text = f"""
VALIDATION RESULTS SUMMARY

Tests Passed: {tests_passed}/{tests_total} ({tests_passed/tests_total*100:.0f}%)

Correlation Test
  Avg correlation: {avg_pearson:.3f}

Predictive Power
  High risk: {high_risk_val:+.1f}% change
  Low risk: {low_risk_val:+.1f}% change

Historical Validation
  SRI major drops: {avg_sri_major_drops:.1f}
  SRI normal years: {avg_sri_normal:.1f}

Status: {'VALIDATED' if tests_passed >= 3 else 'NEEDS WORK'}
"""
ax6.text(0.1, 0.5, summary_text, fontsize=11, family='monospace',
         verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))

plt.tight_layout()
plt.savefig('sri_validation.png', dpi=300, bbox_inches='tight')
print("‚úì Saved: sri_validation.png")

print("\n" + "="*70)
print("‚úÖ VALIDATION COMPLETE!")
print("="*70)
